# -*- coding: utf-8 -*-
"""Random Forest Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bt-RA24W8NSycgEKrBbbZ4CQXrxHrZ4y
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
import os

# 1. Load data
df = pd.read_csv("/content/Fire Data/ML_input.csv")

# 2. Identify relevant column groups
weather_prefixes = ['Tx_', 'Tn_', 'RHx_', 'RHn_', 'Rain_', 'U2_']
vegetation_cols = [col for col in df.columns if 'ndvi_' in col]
weather_cols = [col for col in df.columns if any(col.startswith(prefix) for prefix in weather_prefixes)]
terrain_cols = ['ASPECT', 'Slope', 'TWI']
landcover_cols = [col for col in df.columns if 'LC_' in col]
Fire_Occurance_cols = ['Fire_Occurance']

# 4. Prepare features & target
feature_cols = weather_cols + terrain_cols + landcover_cols + vegetation_cols
X = df[feature_cols]
y = df[Fire_Occurance_cols]

# Fit the model and get feature importances
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X, y)

# Make sure to get the features directly from the model input
feature_names = X.columns.tolist()
importances = rf.feature_importances_

# Check if lengths match
if len(importances) == len(feature_names):
    vi_df = pd.DataFrame({
        'Feature': feature_names,
        'MeanDecreaseGini': importances
    }).sort_values(by='MeanDecreaseGini', ascending=False)
    print(vi_df)
else:
    print("Length mismatch between feature names and importances!")
    print(f"Features: {len(feature_names)}, Importances: {len(importances)}")

# 5. Export results
vi_df.to_csv("variable_Importance.csv", index=False)

#Fire Index Formulation

from sklearn.preprocessing import MinMaxScaler

# 6. Normalize all feature values used in the Fire Index
scaler = MinMaxScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=feature_names)

# 7. Match importance weights to feature columns
vi_dict = dict(zip(vi_df['Feature'], vi_df['MeanDecreaseGini']))

# 8. Generate weighted fire index
X_scaled['Weighted_Contribution'] = 0  # initialize

for feature in X_scaled.columns:
    weight = vi_dict.get(feature, 0)
    X_scaled['Weighted_Contribution'] += X_scaled[feature] * weight

# 9. Normalize Fire Index to 0â€“1 range
df['Fire_Index'] = (X_scaled['Weighted_Contribution'] - X_scaled['Weighted_Contribution'].min()) / (
    X_scaled['Weighted_Contribution'].max() - X_scaled['Weighted_Contribution'].min()
)

# 10. Classify Fire Danger Levels
# Use quantiles to break into 5 fire danger levels
bins = [0.0, 0.29, 0.49, 0.69, 0.89, 1.0]
labels = ['Very Low', 'Low', 'Moderate', 'High', 'Very High']
df['Fire_Level'] = pd.cut(df['Fire_Index'], bins=bins, labels=labels, include_lowest=True)

# 10. Add a Feature ID if not already present
if 'Feature_ID' not in df.columns:
    df['Feature_ID'] = df.index

# 11. Save to file
df[['FID', 'Fire_Index', 'Fire_Level']].to_csv("fire_index.csv", index=False)